{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5a8c1a0-94bd-47a0-a6c2-27d0db218e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mailbox\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1610aa1-cc77-43d8-a4d0-75a1d33ebd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using OpenAI's low cost model\n",
    "\n",
    "mbox_loc = \"PUT THE PATH TO THE .mbox FILES HERE\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\"\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71424f34-5911-45ba-b0a3-6a0df6c05d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that extracts the emails data\n",
    "\n",
    "def extract_emails(mbox_file):\n",
    "    mbox = mailbox.mbox(mbox_file)\n",
    "    emails = []\n",
    "    for message in mbox:\n",
    "        email_data = {\n",
    "            \"subject\": message.get(\"subject\", \"\"),\n",
    "            \"from\": message.get(\"from\", \"\"),\n",
    "            \"to\": message.get(\"to\", \"\"),\n",
    "            \"date\": message.get(\"date\", \"\"),\n",
    "            \"body\": get_email_body(message),\n",
    "        }\n",
    "        emails.append(email_data)\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a4e4c0d-ba69-4e9c-94b3-e6af2b7988b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used during the extraction\n",
    "\n",
    "def get_email_body(message):\n",
    "    if message.is_multipart():\n",
    "        for part in message.walk():\n",
    "            if part.get_content_type() == \"text/plain\":\n",
    "                return part.get_payload(decode=True).decode(errors=\"replace\")\n",
    "    else:\n",
    "        return message.get_payload(decode=True).decode(errors=\"replace\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03164a7b-fcf0-491b-997f-46190b4d3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the extraction\n",
    "\n",
    "sentmail=extract_emails(mbox_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53d1c915-39e8-41bf-8b76-d71cb37b62d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': 'Re: Enjoy your ...', 'from': 'David Stitt <dave.stitt@gmail.com>', 'to': 'John OBrien <john3obrien@gmail.com>', 'date': 'Thu, 30 Mar 2023 22:03:14 -0400', 'body': 'Thank you sir - hope to see you all next time you are in town!\\n\\nOn Thu, Mar 30, 2023 at 2:44\\u202fPM John OBrien <john3obrien@gmail.com> wrote:\\n\\n> .... day, Young Man!!!\\n>\\n> Hope you and yours are well.\\n>\\n> Miss you, Brother!\\n>\\n> Much Love,\\n> Joy, John, Jan Braxton, Ian Joaquin, Ivan Xavier, John Stone, and\\n> Josephine Simone\\n>\\n\\n\\n-- \\n*Dave*\\n*---------------------------------------------------------------------*\\n*Fingerprint:*\\n*16AE **24E3 **7B41 **69D7 **DA86 **6566 **823C **9475 **09F6 **4670*\\n'}\n"
     ]
    }
   ],
   "source": [
    "# a quick test - this should show an email\n",
    "\n",
    "print(sentmail[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "151f8907-8a8a-49f7-816f-d18e856c6cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform emails into Documents\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=email[\"body\"],  # Use the email body as the main content\n",
    "        metadata={\n",
    "            \"subject\": email[\"subject\"],\n",
    "            \"from\": email[\"from\"],\n",
    "            \"to\": email[\"to\"],\n",
    "            \"date\": email[\"date\"],\n",
    "        }\n",
    "    )\n",
    "    for email in sentmail\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79ad42-360e-4aaf-a4bc-a4156e93e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is not necessary unless your emails are really long. If you don't use it you can comment them out\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f8447-5c42-4a48-a5a8-44fa546442fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick test to make sure the chunkc look like you want them. As mentioned above, comment this out if not using chunking.\n",
    "\n",
    "for chunk in chunks[:5]:  # Print the first 5 chunks\n",
    "    print(chunk.page_content)\n",
    "    print(\"Metadata:\", chunk.metadata)\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23e2d64e-19dd-401b-9362-e77b1b753172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 1747 documents\n"
     ]
    }
   ],
   "source": [
    "# Put the chunks of data into a Vector Store that associates a Vector Embedding with each chunk\n",
    "# Chroma is a popular open source Vector Database based on SQLLite\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# If you would rather use the free Vector Embeddings from HuggingFace sentence-transformers\n",
    "# Then uncomment this line instead\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Delete if already exists\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create vectorstore\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=documents, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20f88d26-1b9e-411e-8173-dc91746a119c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,747 vectors with 1,536 dimensions in the vector store\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate the vectors\n",
    "\n",
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5055a372-55ca-4e1b-b189-336489eed664",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "\n",
    "# Thought about categorizing but have not decided if it's necessary or how to categrorize.\n",
    "#doc_types = [metadata['doc_type'] for metadata in metadatas]\n",
    "#colors = [['blue', 'green', 'red', 'orange'][['products', 'employees', 'contracts', 'company'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "34458126-0b96-42de-8aad-63e52bae2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.7, model_name=MODEL)\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG; k is how many chunks to use\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 25})\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 3.5 LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2e2b5-c262-4e91-bef6-8b06d5c0121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a simple question\n",
    "\n",
    "query = \"Ask a specific question about one of your emails. Example: how many emails are there from person@person.xom?\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97fecf0e-0283-4a43-907a-71603d3e284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeps track of the chat history\n",
    "\n",
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d5376d3-df74-47ee-a3ed-9b6ea87d96a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Use in a gradio interface\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa099a-d718-43f3-996d-97be7cd66be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
